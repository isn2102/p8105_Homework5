---
title: "Homework5"
author: "Isabel Nelson"
date: "11/10/2020"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)

# Set how graphs are printed in knitted file
knitr::opts_chunk$set(
  fig.width = 10,
  fig.asp = .6,
  out.width = "90%"
)

#Set global theme for plots
theme_set(theme_minimal(base_size = 18) + theme(
  legend.position = "bottom", 
  axis.text.x = element_text(angle = 90, vjust = 1, hjust = 1)))

#Set options for all plots
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

#Set options for all plots
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

set.seed(1)
```

### Problem 1
Read in the data, from course website, originally from Washington Post. (Note: case_when is basically an if/then statement to create a new variable "resolved" that has a specific value when "disposition" is a certain value.) 
```{r, message = FALSE}
homicide_df <- 
  read_csv("data1/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved", 
      disposition == "Open/No arrest" ~ "unsolved", 
      disposition == "Closed by arrest" ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```

Explore the dataset
```{r, message = FALSE}
aggregate_df <-
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(), 
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Try prop test for a single city. This gives some statistics, particularly of interest a confidence interval for the estimated proportion for unsolved homicides in that city. Use broom::tidy to make the output of prop.test easily extractable for other uses (tibble).
```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Now do iteration. Going straight to a map, not doing the intermediate step of creating a for loop. In this case map takes pair of input columns (hom_unsolved and hom_total), outputs a column (prop_tests) which is added to the dataframe.
```{r}
aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y))
  )
```

Use map to clean up every entry in the prop_tests column. Now we have a list with a bunch of tibbles (tidy_tests output) inside the list. Unnest expands all those into their own rows.
```{r}
results_df <-
aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```

Now we can visualize the results in ggplot.
```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high))
```

### Problem 2
Import datasets. Create a dataframe that has the names of all the files in the data folder of interest. Mutate to create a column with the appropriate relative path name. Create a new variable for what treatment arm the participant is in and ID. Map read_csv to each path name resulting in a dataframe with one column with the file name and one column with the dataframe for each participant. Tidy the final dataset by pivoting and remove unneeded columns. 

```{r, message = FALSE}
paths_df <-
  tibble(
    path = list.files("data2")) %>% 
  mutate(
    path = str_c("data2/", path), 
    num = str_sub(path, -6, -5),
    arm = case_when(
      str_detect(path, "con") ~ "control",
      str_detect(path, "exp") ~ "experimental"),
    id = str_c(arm, num, sep = "_"), 
    data = map(path, read_csv)) %>% 
  unnest(data) %>% 
  pivot_longer(
    week_1:week_8, 
    names_to = "obs_week", 
    values_to = "obs_value") %>% 
  select(-path, -num) 
```

Create the graph to visualize participant observations by week.
```{r, message = FALSE}
paths_df %>% 
ggplot(aes(x = obs_week, y = obs_value)) + 
  geom_line() + 
  aes(colour = arm) + 
  xlab("Observation Time Point") +
  ylab("Value") +
  labs(title = "Subject observations over time") +
  aes(group = factor(id))
```
From this graph we can see that generally participants in the experimental arm had higher values than those in the control arm over the study period. This is especially noticeable in the later weeks. At the beginning both arms were closer together and participant values were overlapping, but as the observations continue in time, the groups diverge and by week 8 there is no overlap between participants in control versus experimental arms - all 10 experimental participants have values that are higher than the control arm participants. 

### Problem 3
Create a base function that takes in n, mu, and sigma (n and sigma pre-specified) and outputs a tibble with the results from a t-test where the null mean is zero and alpha = 0.05.
```{r}
sim_mean_pval <- function(n = 30, mu, sigma = 5) {
  
  sim_data <- tibble(
    x = rnorm(n, mean = mu, sd = sigma),
  )
  
  sim_data %>% 
    t.test(mu = 0, conf.level = 0.95) %>% 
    broom::tidy() %>% 
    select(estimate, p.value)
}
```

Run the simulation: create a tibble with different mean value options, then perform the function operation 5000 times for each mean value using map. Condense these into a dataframe, remove the list column and unnest. 
```{r}
sim_results <- 
  tibble(
    mean_val = c(0, 1, 2, 3, 4, 5, 6)
  ) %>% 
  mutate(
    output_list = map(.x = mean_val, ~ rerun(10, sim_mean_pval(mu = .x))),
    output_df = map(output_list, bind_rows)
  ) %>% 
  select(-output_list) %>% 
  unnest(output_df)
```

## TO DO
* Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis. Describe the association between effect size and power.  
* Make a plot showing the average estimate of μ̂  on the y axis and the true value of μ on the x axis. Make a second plot (or overlay on the first) the average estimate of μ̂  only in samples for which the null was rejected on the y axis and the true value of μ on the x axis. Is the sample average of μ̂  across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?  
```{r}

```

